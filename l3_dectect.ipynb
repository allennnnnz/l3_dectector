{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 載入資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "writer = SummaryWriter(\"logs\")\n",
    "\n",
    "#定義dataset類別\n",
    "class MyData(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, image_dir, label_dir, transform):\n",
    "        self.root_dir = root_dir#根資料夾的路徑\n",
    "        self.image_dir = image_dir#每張圖片的index\n",
    "        self.label_dir = label_dir#label資料夾\n",
    "        self.label_path = os.path.join(self.root_dir, self.label_dir)\n",
    "        self.image_path = os.path.join(self.root_dir, self.image_dir)\n",
    "        #讀出個資料夾為一個列表\n",
    "        self.image_list = os.listdir(self.image_path)\n",
    "        self.label_list = os.listdir(self.label_path)\n",
    "        self.transform = transform\n",
    "        # 因为label 和 Image文件名相同，进行一样的排序，可以保证取出的数据和label是一一对应的\n",
    "        self.image_list.sort()\n",
    "        self.label_list.sort()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_list[idx]\n",
    "        label_name = self.label_list[idx]\n",
    "        img_item_path = os.path.join(self.root_dir, self.image_dir, img_name)\n",
    "        label_item_path = os.path.join(self.root_dir, self.label_dir, label_name)\n",
    "        img = Image.open(img_item_path)\n",
    "\n",
    "        with open(label_item_path, 'r') as f:\n",
    "            label = f.readline()\n",
    "\n",
    "        # img = np.array(img)\n",
    "        img = self.transform(img)\n",
    "        sample = {'img': img, 'label': label}\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        assert len(self.image_list) == len(self.label_list)\n",
    "        return len(self.image_list)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n",
    "    root_dir = \"train\"\n",
    "    image_ants = \"train\\L3\"\n",
    "    label_ants = \"ants_label\"\n",
    "    ants_dataset = MyData(root_dir, image_ants, label_ants, transform)\n",
    "    image_bees = \"bees_image\"\n",
    "    label_bees = \"bees_label\"\n",
    "    bees_dataset = MyData(root_dir, image_bees, label_bees, transform)\n",
    "    train_dataset = ants_dataset + bees_dataset\n",
    "\n",
    "    # transforms = transforms.Compose([transforms.Resize(256, 256)])\n",
    "    dataloader = DataLoader(train_dataset, batch_size=1, num_workers=2)\n",
    "\n",
    "    writer.add_image('error', train_dataset[119]['img'])\n",
    "    writer.close()\n",
    "    # for i, j in enumerate(dataloader):\n",
    "    #     # imgs, labels = j\n",
    "    #     print(type(j))\n",
    "    #     print(i, j['img'].shape)\n",
    "    #     # writer.add_image(\"train_data_b2\", make_grid(j['img']), i)\n",
    "    #\n",
    "    # writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard)\n",
      "  Downloading grpcio-1.62.0-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\anaconda\\lib\\site-packages (from tensorboard) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in e:\\anaconda\\lib\\site-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in e:\\anaconda\\lib\\site-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in e:\\anaconda\\lib\\site-packages (from tensorboard) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in e:\\anaconda\\lib\\site-packages (from tensorboard) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\anaconda\\lib\\site-packages (from tensorboard) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in e:\\anaconda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/5.5 MB 653.6 kB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.2/5.5 MB 1.8 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.4/5.5 MB 2.3 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.5/5.5 MB 2.6 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.7/5.5 MB 2.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.0/5.5 MB 3.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.3/5.5 MB 3.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.6/5.5 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 2.1/5.5 MB 4.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.3/5.5 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.7/5.5 MB 5.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.2/5.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.4/5.5 MB 5.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.6/5.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.9/5.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.1/5.5 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.2/5.5 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.4/5.5 MB 5.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.6/5.5 MB 5.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.6/5.5 MB 5.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.8/5.5 MB 4.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.9/5.5 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.0/5.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.0/5.5 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.1/5.5 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.2/5.5 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.3/5.5 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.4/5.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
      "   ------------------------ --------------- 81.9/133.7 kB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 133.7/133.7 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.62.0-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/3.8 MB 1.5 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.2/3.8 MB 1.6 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.2/3.8 MB 1.9 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.3/3.8 MB 1.8 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.4/3.8 MB 1.8 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.5/3.8 MB 1.9 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.6/3.8 MB 1.9 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.7/3.8 MB 1.9 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.8/3.8 MB 1.9 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.9/3.8 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.0/3.8 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 1.1/3.8 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 1.2/3.8 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 1.4/3.8 MB 2.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.5/3.8 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 1.6/3.8 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 1.7/3.8 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.8/3.8 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.9/3.8 MB 2.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.1/3.8 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 2.2/3.8 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.3/3.8 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.4/3.8 MB 2.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.6/3.8 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.7/3.8 MB 2.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.8/3.8 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.0/3.8 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.1/3.8 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.2/3.8 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.4/3.8 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 3.5/3.8 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.6/3.8 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.7/3.8 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.8/3.8 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 2.4 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Installing collected packages: tensorboard-data-server, grpcio, absl-py, tensorboard\n",
      "Successfully installed absl-py-2.1.0 grpcio-1.62.0 tensorboard-2.16.2 tensorboard-data-server-0.7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "class MyData(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, label_dir):\n",
    "        self.root_dir = root_dir#根資料夾名\n",
    "        self.label_dir = label_dir#Label資料夾名\n",
    "        self.image_dir_path = os.path.join(self.root_dir, self.label_dir)#組合出圖片資料夾地址\n",
    "        #讀出個資料夾為一個列表\n",
    "        self.image_list = os.listdir(self.image_dir_path)#將圖片資料夾中的內容形成一個列表\n",
    "        self.image_list.sort()\n",
    "\n",
    "    #取得某張圖片\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_list[idx]#圖片檔名\n",
    "        img_item_path = os.path.join(self.root_dir, self.label_dir, img_name)#定位圖片完整地址\n",
    "        img = Image.open(img_item_path)\n",
    "        label = self.label_dir#label資料夾名就是圖片對應的label\n",
    "        return img , label\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"E:/run_dataset_totalseg/train\"\n",
    "L0_label_dir = 'L0'\n",
    "L1_label_dir = 'L1'\n",
    "L1_L2_label_dir = 'L1_L2'\n",
    "L2_label_dir = 'L2'\n",
    "L2_L3_label_dir = 'L2_L3'\n",
    "L3_label_dir = 'L3'\n",
    "L3_L4_label_dir = 'L3_L4'\n",
    "L4_label_dir = 'L4'\n",
    "L4_L5_label_dir = 'L4_L5'\n",
    "L5_label_dir = 'L5'\n",
    "T12_label_dir = 'T12'\n",
    "T12_L1_label_dir = 'T12_L1'\n",
    "\n",
    "L0_dataset = MyData(root_dir,L0_label_dir)\n",
    "L1_dataset = MyData(root_dir,L1_label_dir)\n",
    "L1_L2_dataset = MyData(root_dir,L1_L2_label_dir)\n",
    "L2_dataset = MyData(root_dir,L2_label_dir)\n",
    "L2_L3_dataset = MyData(root_dir,L2_L3_label_dir)\n",
    "L3_dataset = MyData(root_dir,L3_label_dir)\n",
    "L3_L4_dataset = MyData(root_dir,L3_L4_label_dir)\n",
    "L4_dataset = MyData(root_dir,L4_label_dir)\n",
    "L4_L5_dataset = MyData(root_dir,L4_L5_label_dir)\n",
    "L5_dataset = MyData(root_dir,L5_label_dir)\n",
    "T12_dataset = MyData(root_dir,T12_label_dir)\n",
    "T12_L1_dataset = MyData(root_dir,T12_L1_label_dir)\n",
    "\n",
    "other_dataset = L0_dataset + L1_dataset + L1_L2_dataset + L2_dataset + L2_L3_dataset + L3_L4_dataset + L4_dataset + L4_L5_dataset + L5_dataset + T12_dataset + T12_L1_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L3 <__main__.MyData object at 0x000002B819A53510>\n",
      "other <torch.utils.data.dataset.ConcatDataset object at 0x000002B81B8AE950>\n"
     ]
    }
   ],
   "source": [
    "l3_len = len(L3_dataset)\n",
    "print(\"L3\",l3_len)\n",
    "other_len = len(other_dataset)\n",
    "print(\"other\",other_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full path E:/run_dataset_totalseg/train\\L3\\s0001_140_L3.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "root_dir = \"E:/run_dataset_totalseg/train\"\n",
    "label_dir = 'L3'\n",
    "image_path = os.path.join(root_dir,label_dir)\n",
    "img_list = os.listdir(image_path)\n",
    "fullpath = os.path.join(image_path,img_list[0])\n",
    "print(\"full path\",fullpath)\n",
    "img = Image.open(fullpath)\n",
    "img.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
